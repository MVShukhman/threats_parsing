from base import Base
from bs4 import BeautifulSoup as bs
import requests


class MalwarebytesParser(Base):
    _identifier = 'malwarebytes'
    _base_url = 'https://blog.malwarebytes.com/detections/'
    tmp = 1

    def _get_links(self, url) -> list:
        links = []
        resp = requests.get(url, headers=self._header)
        code = resp.content
        soup = bs(code, 'html.parser')
        table = soup.find('section', {'id': 'detections'})
        table = table.find('div', {'class': 'container'})
        table = table.find('div', {'class': 'row'})
        rows = table.find_all('div', {'class': 'col-md-4'})
        for row in rows:
            links.extend([x.a['href'] for x in row.find_all('li')])
        self.n = len(links)
        return links

    def _parse_by_link(self, url) -> dict:
        resp = requests.get(url, headers=self._header)
        code = resp.content
        soup = bs(code, 'html.parser')
        table = soup.find('div', {'class': 'col-md-9 col-md-offset-2 col-xs-12 right-side-content'})
        table = table.find('div', {'class': 'row'})
        table = table.find('div', {'class': 'col-md-9'})
        name = table.h1.text
        rows = table.find_all('div', {'class': 'row'})
        print(name)
        ans = {
            'name': name,
            'url': url,
            'source_keyword': self._identifier,
            'info': {}
        }

        for row in rows:
            key = row.h3.text
            value = row.text
            ans['info'][key] = value

        print('{}/{}'.format(str(self.tmp), str(self.n)))
        self.tmp += 1

        return ans


def main():
    parser = MalwarebytesParser()
    parser.run_parsing()


if __name__ == '__main__':
    main()
