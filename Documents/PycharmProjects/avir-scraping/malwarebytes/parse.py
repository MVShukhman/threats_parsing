from bs4 import BeautifulSoup
import json
import requests


class MalwareParser:
    links = []
    user_agent = ('Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:50.0) '
              'Gecko/20100101 Firefox/50.0')
    storage = []

    def __init__(self):
        self.get_links()

    def get_links(self):
        resp = requests.get('https://blog.malwarebytes.com/detections/', headers={'User-Agent': self.user_agent})
        soup = BeautifulSoup(resp.content, 'html.parser')
        blocks = soup.find_all('div', {'class': 'col-md-4'})
        for block in blocks:
            self.links.extend([x.a['href'] for x in block.find_all('li')])

    def extract_data(self, url):
        resp = requests.get(url, headers={'User-Agent': self.user_agent})
        soup = BeautifulSoup(resp.content, 'html.parser')
        data = {}
        block = soup.find('div', {'class': 'col-md-9'})
        name = block.h3.text
        rows = block.find_all('div', {'class': 'row'})
        fields = [(x.h3.text, x.text) for x in rows] + [('name', name)]
        self.storage.append(dict(fields))

    def fill_storage(self):
        for i, link in enumerate(self.links):
            self.extract_data(link)
            print(i + 1, '/', len(self.links))

    def dump(self):
        with open('data.json', 'w') as jsonfile:
            json.dump(self.storage, jsonfile)


parser = MalwareParser()
parser.fill_storage()
parser.dump()
